
>[!exm|1]
>Consider: $$f(x) =  \begin{cases}  0& x \le 0\\ e^\frac{-1}{x} & x > 0 \end{cases}$$Whose graph resembles:
>![[Pasted image 20240403143347.png]]
>
>We claim $f(x)$ is $C^\infty ( \mathbb{R})$ but that it is not Real Analytic.

>[!claim|*]- Proof of Example 1
>`\begin{proof}`
>We need to show that the Taylor Series of $f(x)$ centered at $0$ is not equal to $f(x)$. Now:$$f'(x) = \frac{1}{x^2}e^{-\frac{1}{x}}$$Inductively, we can show that: $$f^k(x) = P_k(\frac{1}{x})e^{-\frac{1}{x}}$$Where $P_k(\frac{1}{x})$ is a polynomial in $\frac{1}{x}$ and $\therefore$ continuous for $x > 0$. In order to calculate the Taylor Polynomial, we first note that $f(0) = 0$. We need to take the limit from both directions to find $f'(0)$ (if they do not match up the derivative does not exist):$$\text{Right}: \; \; \lim_{h \rightarrow 0^+} \frac{f(h)-f(0)}{h} = \lim_{h \rightarrow 0^+} \frac{e^{-\frac{1}{h}}}{h} \; \; \text{let} \; x = \frac{1}{h} \implies \lim_{x \rightarrow \infty} xe^{-x} = 0$$Which holds by hospital’s rule. Now: $$\text{Left}: \; \; \text{I am not going to even bother writing it, it's} \; 0$$If $f^k(0) = 0$, then the left side is **clearly** $0$. Now for the right side: $$\lim_{h \rightarrow 0^+} \frac{f^k(h)-f^k(0)}{h} = \lim_{h \rightarrow 0^+} \frac{P_k(\frac{1}{h})e^{-\frac{1}{h}}}{h} \implies \lim_{x \rightarrow \infty} P_k(x)xe^{-x} = 0 \; \; \text{by letting} \; x = \frac{1}{h}$$The Taylor series of $f(x)$ at $0$ is given by: $$\sum_{k=0}^\infty \frac{f^k(0)}{k!}x^k=0 \ne f(x) \; \; \text{when} \; x>0$$Which holds since every derivative at $0$ is $0$. 
>As an exercise, you can calculate the radius of convergence to be $+\infty$.
>`\end{proof}`

The moral of the story: Not every $C^\infty$ function is real analytic. 

#### Ordinary Differential Equations?!?!?!??!!??!?!?!??!

>[!def|*] First order initial value problem (IVP)
>We recall: $$y'(t) = F(t,y(t)) \; \; \text{with}\; y(t_0) = y_0$$
>With $t_0, y_0 \in \mathbb{R}$ and are called the initial conditions. 

>[!exm|*]
>Consider our familiar $y’= \frac{1}{t}$ with $y(0) = 0$. It is trivial to show that there is no solution (integrate and you will see the problem when plugging in the initial conditions).

So what conditions guarantee that a solution exists and is unique? (For all my Apple Math people, incoming existence and uniqueness theorem).

>[!def|*] Lipschitz
>Let $A \subseteq R$ be an interval and $f: A \rightarrow \mathbb{R}$. $f$ is Lipschitz on $A$ if $\exists \: L > 0$ so that: $$|f(x) - f(y) \le L|x-y| \; \; \forall \:x,y \in A$$

>[!exm|*]- Showing Lipschitz
>We show that $f(x) = x^2$ is Lipschitz on $[-1,1]$. 
>
>`\begin{proof}`
>For any $x,y \in [-1,1]$, $\exists \: z$ between $x \; \land \; y$. For simplicity, assume $x < y$. Then: $$\frac{f(y)-f(x)}{y-x} = f'(z)$$Which holds by the mean value theorem. Now let: $$L = \text{sup}\{|f'(z)|: z \in [0,1]\}$$Then: $$\left| \frac{f(x)-f(y)}{x-y} \right|  \le L \; \; \text{for any}\; x,y \in [0,1] $$Thus: $$|f(x)-f(y)| \le 2|x-y|$$Since $f’(z) = 2z$. 
>>`\end{proof}`

>[!exm|*]- Showing Not Lipschitz
>We claim that $f(x) = \sqrt x$ is not Lipschitz on $[0,1]$. 
>
>`\begin{proof}` By Contradiction
>Assume $\sqrt x$ is Lipschitz on $[0,1]$, then: $$|\sqrt x - \sqrt y| \le L |x-y| \; \; \text{for some} \; L > 0$$(The problem will come when $x = 0$). Let $x = 0$, then: $$|\sqrt y| \le L|y| \; \; \forall \: y \in [0,1]$$Clearly $y = 0 \; \land \; y =1$ causes no problem. In particular, if $y \in (0,1]$, then: $$\frac{\sqrt y}{y} \le L \implies \frac{1}{\sqrt y} \le L$$If $L \ge 1$, let $y = \frac{1}{4L^2} \in (0,1]$ and then we get: $$\frac{1}{\sqrt{\frac{1}{4L^2}}} = 2L \not\le L$$This contradicts $L>0$. Now if $L < 1$, take $y = 1$.  Then $1 \le L < 1$ which is a contradiction as well.
>
>Then it is not Lipschitz continuous. 
>`\end{proof}`
